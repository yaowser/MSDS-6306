{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "interested-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_html(url):    # requests and response from url\n",
    "    r = requests.get(url)\n",
    "    if r.ok:    # catch \n",
    "        return r.text\n",
    "    print(r.status_code)\n",
    "\n",
    "def get_data(html):    # func.parse html code\n",
    "    df = []\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    trs = soup.find('table').find('tbody').find_all('tr')    # find tags for parse data\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        \n",
    "        try:     # parse symbol from page\n",
    "            symbol = tds[0].find('a').text\n",
    "        except:\n",
    "            symbol = ''    # if info none, catche exception\n",
    "        try:    # parse price from page\n",
    "            name = tds[1].find('title').text #HELP\n",
    "        except:\n",
    "            name = ''\n",
    "        try:    # parse price from page\n",
    "            price = tds[2].find('span').text \n",
    "        except:\n",
    "            price = ''\n",
    "        try:    # parse price from page\n",
    "            change = tds[3].find('span').text \n",
    "        except:\n",
    "            change = ''\n",
    "        try:    # parse price from page\n",
    "            perchange = tds[4].find('span').text \n",
    "        except:\n",
    "            perchange = ''\n",
    "        try:    # parse price from page\n",
    "            volume = tds[5].find('span').text \n",
    "        except:\n",
    "            volume = ''\n",
    "        try:    # parse price from page\n",
    "            avgvol = tds[6].find('span').text  #HELP\n",
    "        except:\n",
    "            avgvol = ''\n",
    "        try:    # parse price from page\n",
    "            marketcap = tds[7].find('span').text \n",
    "        except:\n",
    "            marketcap = ''\n",
    "        try:    # parse price from page\n",
    "            PEratio = tds[8].find('span').text  #HELP\n",
    "        except:\n",
    "            PEratio = ''\n",
    "        try:    # parse url from page\n",
    "            url = 'https://finance.yahoo.com' + tds[0].find('a').get('href')\n",
    "        except:\n",
    "            url = ''\n",
    "        data = [symbol,name,price,change,perchange,volume,avgvol,marketcap,PEratio,url] #verbose for debugging\n",
    "        df.append(data)\n",
    "    return(df)\n",
    "\n",
    "df = pd.DataFrame()   \n",
    "for cnt_page in range(0, 275, 25):\n",
    "    data = get_data(get_html('https://finance.yahoo.com/most-active?count=25&offset='+str(cnt_page)))\n",
    "    data = pd.DataFrame(data,columns=['Symbol','Name','Price','Change','% Change','Volume','Avg Vol','Market Cap','PE Ratio','url'])\n",
    "    df = df.append(data).reset_index(drop=True)\n",
    "\n",
    "df.reset_index().rename(columns={'index':datetime.now().strftime(\"%m-%d-%Y\")}).to_csv('finance_yahoo'+datetime.now().strftime(\"%m-%d-%Y-%H%M\")+'.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
